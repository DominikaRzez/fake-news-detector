{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4595150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nltk for text cleaning\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# wordcloud creation libraries\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6011f710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reuters highlight u president donald trump adm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washington reuters republican political consul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moscow reuters russian troop took part war gam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>st century wire say democratic party establish...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitt romney top adviser election accepted reas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  reuters highlight u president donald trump adm...      0\n",
       "1  washington reuters republican political consul...      0\n",
       "2  moscow reuters russian troop took part war gam...      0\n",
       "3  st century wire say democratic party establish...      1\n",
       "4  mitt romney top adviser election accepted reas...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78379648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a sample of the data for X & y\n",
    "X = dataset.iloc[:35000,0]\n",
    "y = dataset.iloc[:35000,1]\n",
    "\n",
    "# Run vectorizer so we can convert the text into numerical features\n",
    "vectorizer = TfidfVectorizer(max_features = 50000 , lowercase=False , ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fffdfff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    reuters highlight u president donald trump adm...\n",
       "1    washington reuters republican political consul...\n",
       "2    moscow reuters russian troop took part war gam...\n",
       "3    st century wire say democratic party establish...\n",
       "4    mitt romney top adviser election accepted reas...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View X data (articles)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93659f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View y data (real/fake news flag) 0 = True, 1 = False\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed34de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28000,), (7000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the variables for train, test & split\n",
    "train_data , test_data , train_label , test_label = train_test_split(X , y , test_size = 0.2 ,random_state = 0)\n",
    "train_data.shape , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb08f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data\n",
    "vector_train = vectorizer.fit_transform(train_data)\n",
    "vector_train = vector_train.toarray()\n",
    "\n",
    "# Transform the test data\n",
    "vector_test = vectorizer.transform(test_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa53b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes for the test & train data\n",
    "training_data = pd.DataFrame(vector_train , columns=vectorizer.get_feature_names())\n",
    "testing_data = pd.DataFrame(vector_test , columns= vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62e09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Multinomial Naive Bayes model\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(training_data, train_label)\n",
    "y_pred  = clf.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2f06113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3661\n",
       "0    3339\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the prediction\n",
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63697a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3654\n",
       "0    3346\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the test\n",
    "test_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ccb2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3346\n",
      "           1       0.96      0.96      0.96      3654\n",
      "\n",
      "    accuracy                           0.95      7000\n",
      "   macro avg       0.95      0.95      0.95      7000\n",
      "weighted avg       0.95      0.95      0.95      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for the test data\n",
    "print(classification_report(test_label , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312aeb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     13601\n",
      "           1       0.96      0.96      0.96     14399\n",
      "\n",
      "    accuracy                           0.96     28000\n",
      "   macro avg       0.96      0.96      0.96     28000\n",
      "weighted avg       0.96      0.96      0.96     28000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for the training data\n",
    "y_pred_train = clf.predict(training_data)\n",
    "print(classification_report(train_label , y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e5cec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score for the training data\n",
    "accuracy_score(train_label , y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e8fe445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547142857142857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score for the test data\n",
    "accuracy_score(test_label , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ca4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(clf , 'multinomial-NB-model.pkl')\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, open(\"multinomial-NB-pickle.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a838420",
   "metadata": {},
   "source": [
    "### Manually testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6ac1cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jfrgr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# create the values for the text cleaning\n",
    "ps = WordNetLemmatizer()\n",
    "stopwords = stopwords.words(\"english\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Define a funtion to clean the text\n",
    "def cleaning_data(row):\n",
    "    \n",
    "    # convert text to into lower case\n",
    "    row = row.lower() \n",
    "    \n",
    "    # this line of code only take words from text and remove number and special character using RegX\n",
    "    row = re.sub('[^a-zA-Z]' , ' ' , row)\n",
    "    \n",
    "    # split the data and make token.\n",
    "    token = row.split() \n",
    "    \n",
    "    # lemmatise the word and remove stop words like a, an , the , is ,are ...\n",
    "    news = [ps.lemmatize(word) for word in token if not word in stopwords]  \n",
    "    \n",
    "    # finaly join all the token with space\n",
    "    cleaned_news = ' '.join(news) \n",
    "    \n",
    "    # return cleanned data\n",
    "    return cleaned_news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a8985af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go writing article collecting text news article online'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = cleaning_data(str(\"Have a go at writing an article for yourself, or collecting some text from a news article online!\"))\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "470597eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model says...\n",
      "Your article is a load of rubbish!\n"
     ]
    }
   ],
   "source": [
    "single_prediction = clf.predict(vectorizer.transform([news]).toarray())\n",
    "single_prediction\n",
    "\n",
    "\n",
    "print(\"The model says...\")\n",
    "\n",
    "if single_prediction == 0:\n",
    "    print(\"Your article is legit!\")\n",
    "else:\n",
    "    print(\"Your article is a load of rubbish!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
