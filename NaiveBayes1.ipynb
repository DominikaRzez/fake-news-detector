{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vu9budV6MR0",
        "outputId": "29f4d2d3-1ba0-4a09-9f95-46905f839f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r0% [1 InRelease gpgv 1,575 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 1,575 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 1,575 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (103 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Hashing\").getOrCreate()"
      ],
      "metadata": {
        "id": "N0f4vTT96OgS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
      ],
      "metadata": {
        "id": "BZCl6w8o6hgE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSV\n",
        "from pyspark import SparkFiles\n",
        "df = spark.read.csv(SparkFiles.get(\"/content/news_TextHero.csv\"),sep=\",\", escape='\"', encoding=\"utf-8\", quote='\"',  header=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBpqmVWE6mNi",
        "outputId": "0e163b01-d4f3-4005-f5ba-0383d1c29fd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|               title|                text|subject|      date|news_outcome|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|['donald', 'trump...|['donald', 'trump...|   News|31/12/2017|           1|\n",
            "|['drunk', 'braggi...|['house', 'intell...|   News|31/12/2017|           1|\n",
            "|['sheriff', 'davi...|['friday', 'revea...|   News|30/12/2017|           1|\n",
            "|['trump', 'obsess...|['christmas', 'da...|   News|29/12/2017|           1|\n",
            "|['pope', 'francis...|['pope', 'francis...|   News|25/12/2017|           1|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "df = df.withColumn('length_title', length(df['title']))\n",
        "df = df.withColumn('length_text', length(df['text']))\n",
        "df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYl4gaV4t_Ig",
        "outputId": "ac40afcd-a388-4777-c319-51b780834c08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+----------+------------+------------+-----------+\n",
            "|               title|                text|subject|      date|news_outcome|length_title|length_text|\n",
            "+--------------------+--------------------+-------+----------+------------+------------+-----------+\n",
            "|['donald', 'trump...|['donald', 'trump...|   News|31/12/2017|           1|          87|       2825|\n",
            "|['drunk', 'braggi...|['house', 'intell...|   News|31/12/2017|           1|          91|       1871|\n",
            "|['sheriff', 'davi...|['friday', 'revea...|   News|30/12/2017|           1|          97|       3533|\n",
            "+--------------------+--------------------+-------+----------+------------+------------+-----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezuEienogLQ5",
        "outputId": "d8b91df0-09c6-4ab3-cce8-69ca7b987184"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- subject: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- news_outcome: string (nullable = true)\n",
            " |-- length_title: integer (nullable = true)\n",
            " |-- length_text: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changing the title type to array\n",
        "from pyspark.sql.functions import udf, col, split\n",
        "\n",
        "tolist_udf = udf(lambda x: x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))"
      ],
      "metadata": {
        "id": "m3dBN2BBgOaE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df.withColumn(\"title\", tolist_udf(col(\"title\")))\n",
        "df_2 = df_2.withColumn(\"label\", tolist_udf(col(\"news_outcome\")))"
      ],
      "metadata": {
        "id": "8CNyD2ARgRNL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "df_2 = df_2.withColumn(\"label\", df_2[\"label\"].cast(IntegerType()))"
      ],
      "metadata": {
        "id": "HCM3HKLIsI-e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = df_2.select(split(col(\"title\"),\",\").alias(\"TitleArray\"), \"label\", \"length_title\") \\\n",
        "    .drop(\"title\")\n",
        "df_3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiqSojxzgXEP",
        "outputId": "2246ee5c-58fd-4f80-9365-5ef26ec4d2a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TitleArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- length_title: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hashing Term Frequency"
      ],
      "metadata": {
        "id": "EZYGG2uAnXo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency\n",
        "hashing = HashingTF(inputCol=\"TitleArray\", outputCol=\"TitleHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "ht7JMHaZgbKf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df = hashing.transform(df_3)"
      ],
      "metadata": {
        "id": "TQ8jlM7ugheu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvtwY_Yagi96",
        "outputId": "dc8c9f33-fca5-4f6e-d19c-eaf881ba2735"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+--------------------+\n",
            "|          TitleArray|label|length_title|   TitleHashedValues|\n",
            "+--------------------+-----+------------+--------------------+\n",
            "|[donald,  trump, ...|    1|          87|(32,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|    1|          91|(32,[0,2,10,14,16...|\n",
            "|[sheriff,  david,...|    1|          97|(32,[3,5,6,7,10,1...|\n",
            "+--------------------+-----+------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = df_2.withColumn(\"text\", tolist_udf(col(\"text\")))"
      ],
      "metadata": {
        "id": "UPi9_eYMhTwu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df2 = text_df.select(split(col(\"text\"),\",\").alias(\"TextArray\"), \"label\", \"length_text\") \\\n",
        "    .drop(\"text\")\n",
        "text_df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63NU44dphwyl",
        "outputId": "099244e9-b02b-4245-8fed-4c20796ba1e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TextArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- length_text: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency - text\n",
        "hashing = HashingTF(inputCol=\"TextArray\", outputCol=\"TextHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "TZtCUsSziRNz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text = hashing.transform(text_df2)"
      ],
      "metadata": {
        "id": "O2s3sfc-iRvH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JgWiZsiePY",
        "outputId": "0c9de99a-0092-4b18-d75c-e75cefb7a6ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-----------+--------------------+\n",
            "|           TextArray|label|length_text|    TextHashedValues|\n",
            "+--------------------+-----+-----------+--------------------+\n",
            "|[donald,  trump, ...|    1|       2825|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|    1|       1871|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|    1|       3533|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+-----+-----------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting IDF on the data set"
      ],
      "metadata": {
        "id": "8KsAfVzInfiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set \n",
        "idf = IDF(inputCol=\"TitleHashedValues\", outputCol=\"TitleFeatures\")\n",
        "idfModel = idf.fit(hashed_df)\n",
        "rescaledData = idfModel.transform(hashed_df)"
      ],
      "metadata": {
        "id": "Kc0QOqD_-LHj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cneaizHljY3R",
        "outputId": "0b9a4c8a-db49-4fbc-f70c-93e82bb3964a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+--------------------+--------------------+\n",
            "|          TitleArray|label|length_title|   TitleHashedValues|       TitleFeatures|\n",
            "+--------------------+-----+------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|          87|(32,[4,9,11,13,22...|(32,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|    1|          91|(32,[0,2,10,14,16...|(32,[0,2,10,14,16...|\n",
            "|[sheriff,  david,...|    1|          97|(32,[3,5,6,7,10,1...|(32,[3,5,6,7,10,1...|\n",
            "+--------------------+-----+------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set - text\n",
        "idf2 = IDF(inputCol=\"TextHashedValues\", outputCol=\"TextFeatures\")\n",
        "idfModel2 = idf2.fit(hashed_df_text)\n",
        "rescaledData2 = idfModel2.transform(hashed_df_text)"
      ],
      "metadata": {
        "id": "mC1as3TP-WzS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData2.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg3hn-BEkfc3",
        "outputId": "f879071f-a166-4f65-fc61-6f4c184f481b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-----------+--------------------+--------------------+\n",
            "|           TextArray|label|length_text|    TextHashedValues|        TextFeatures|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|       2825|(32,[0,1,2,3,4,6,...|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|    1|       1871|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|    1|       3533|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "PKyih3mnnjIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['TitleFeatures', 'length_title'], outputCol='features')"
      ],
      "metadata": {
        "id": "ixwCMH7tu2Ot"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner = clean_up.transform(rescaledData)"
      ],
      "metadata": {
        "id": "hM_Ji0G2u6zl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWjRWptKvhsD",
        "outputId": "dcab52f9-681f-4f03-d3e8-8df0450e6044"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+\n",
            "|          TitleArray|label|length_title|   TitleHashedValues|       TitleFeatures|            features|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|          87|(32,[4,9,11,13,22...|(32,[4,9,11,13,22...|(33,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|    1|          91|(32,[0,2,10,14,16...|(32,[0,2,10,14,16...|(33,[0,2,10,14,16...|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaner.randomSplit([0.7, 0.3])\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "1jJPMVGUnsh6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIAjQwCNseGp",
        "outputId": "05d776be-bf58-4e5c-a4ca-e3fbb7eb7021"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|          TitleArray|label|length_title|   TitleHashedValues|       TitleFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|[1,  million,  do...|    1|          94|(32,[1,7,11,15,21...|(32,[1,7,11,15,21...|(33,[1,7,11,15,21...|[-92.428614557579...|[0.71786765147133...|       0.0|\n",
            "|[1,  percenter,  ...|    1|         131|(32,[3,5,6,9,10,1...|(32,[3,5,6,9,10,1...|(33,[3,5,6,9,10,1...|[-119.95077874140...|[0.53936011576607...|       0.0|\n",
            "|[10,  day,  orlan...|    1|          77|(32,[1,10,17,27,2...|(32,[1,10,17,27,2...|(33,[1,10,17,27,2...|[-83.398425002981...|[0.12128236301639...|       1.0|\n",
            "|[10,  reason,  vo...|    1|          71|(32,[0,3,8,9,10,1...|(32,[0,3,8,9,10,1...|(33,[0,3,8,9,10,1...|[-69.769872585833...|[0.42496676601732...|       1.0|\n",
            "|[10,  yr,  old,  ...|    1|         142|(32,[0,1,2,4,5,7,...|(32,[0,1,2,4,5,7,...|(33,[0,1,2,4,5,7,...|[-139.54569109655...|[0.71381576750236...|       0.0|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMomCwsssfU4",
        "outputId": "20cb1db4-fc47-441f-b9bb-433a3d49faff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.642055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature vectors\n",
        "clean_up2 = VectorAssembler(inputCols=['TextFeatures', 'length_text'], outputCol='features')\n",
        "cleaner_text = clean_up2.transform(rescaledData2)"
      ],
      "metadata": {
        "id": "UkYpq-jCwIRa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner_text.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4COXQudwOHY",
        "outputId": "3fd74c9d-7f66-4adc-920d-c9ace4e18633"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-----------+--------------------+--------------------+--------------------+\n",
            "|           TextArray|label|length_text|    TextHashedValues|        TextFeatures|            features|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|       2825|(32,[0,1,2,3,4,6,...|(32,[0,1,2,3,4,6,...|[0.90043953270749...|\n",
            "|[house,  intellig...|    1|       1871|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|[0.65486511469635...|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaner_text.randomSplit([0.7, 0.3])\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "A3Hj11rdwttu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1ZxNqfGw5s-",
        "outputId": "30286d1f-08f5-49cf-d9a5-8a4dc974fd33"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|TextArray|label|length_text|TextHashedValues|        TextFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Tranform the model with the testing data\n",
        "train_results = predictor.transform(training)\n",
        "train_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWSbxvup35IC",
        "outputId": "c916d50d-3d0e-48e1-ee27-164c96ad3118"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|TextArray|label|length_text|TextHashedValues|        TextFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2127030127202...|[0.47463655470847...|       1.0|\n",
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting fake news was: %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKiLHf7qw6u2",
        "outputId": "baa6426a-bbe4-433c-b8b4-c74203d38232"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting fake news was: 0.657543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_eval = MulticlassClassificationEvaluator()\n",
        "train = acc_eval.evaluate(train_results)\n",
        "print(\"Accuracy of model at predicting fake news was: %f\" % train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9L2Of1T3zfX",
        "outputId": "beb9218c-4390-40a2-84ff-161829a1b07f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting fake news was: 0.665101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1')\n",
        "f1 = f1_eval.evaluate(test_results)\n",
        "print(\"F1 score of model at predicting fake news was: %f\" % f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCllPs8pv7E0",
        "outputId": "b7bb592f-08f9-4550-f79b-4bac702c2186"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score of model at predicting fake news was: 0.657543\n"
          ]
        }
      ]
    }
  ]
}