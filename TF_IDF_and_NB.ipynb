{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF_and_NB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vu9budV6MR0",
        "outputId": "fd270ac0-0340-4da0-af47-8109fc47e182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r0% [1 InRelease gpgv 1,575 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 1,575 B] [3 InRelease 15.6 kB/88.7 kB 18%] [Waiting for he\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (113 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Hashing\").getOrCreate()"
      ],
      "metadata": {
        "id": "N0f4vTT96OgS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
      ],
      "metadata": {
        "id": "BZCl6w8o6hgE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSV\n",
        "from pyspark import SparkFiles\n",
        "df = spark.read.csv(SparkFiles.get(\"/content/news.csv\"),sep=\",\", escape='\"', encoding=\"utf-8\", quote='\"',  header=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBpqmVWE6mNi",
        "outputId": "afe4db8e-b715-4e54-aff3-5829d37472dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|               title|                text|subject|      date|news_outcome|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|['donald', 'trump...|['donald', 'trump...|   News|31/12/2017|           1|\n",
            "|['drunk', 'braggi...|['house', 'intell...|   News|31/12/2017|           1|\n",
            "|['sheriff', 'davi...|['friday', 'revea...|   News|30/12/2017|           1|\n",
            "|['trump', 'obsess...|['christmas', 'da...|   News|29/12/2017|           1|\n",
            "|['pope', 'francis...|['pope', 'francis...|   News|25/12/2017|           1|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "df = df.withColumn('length_title', length(df['title']))\n",
        "df = df.withColumn('length_text', length(df['text']))\n",
        "df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYl4gaV4t_Ig",
        "outputId": "d55b42fd-3088-436f-b080-b98023de5972"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+----------+------------+------------+-----------+\n",
            "|               title|                text|subject|      date|news_outcome|length_title|length_text|\n",
            "+--------------------+--------------------+-------+----------+------------+------------+-----------+\n",
            "|['donald', 'trump...|['donald', 'trump...|   News|31/12/2017|           1|          87|       2825|\n",
            "|['drunk', 'braggi...|['house', 'intell...|   News|31/12/2017|           1|          91|       1871|\n",
            "|['sheriff', 'davi...|['friday', 'revea...|   News|30/12/2017|           1|          97|       3533|\n",
            "+--------------------+--------------------+-------+----------+------------+------------+-----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezuEienogLQ5",
        "outputId": "316976a4-a6ac-43c3-8320-79b5376d8c53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- subject: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- news_outcome: string (nullable = true)\n",
            " |-- length_title: integer (nullable = true)\n",
            " |-- length_text: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changing the title type to array\n",
        "from pyspark.sql.functions import udf, col, split\n",
        "\n",
        "tolist_udf = udf(lambda x: x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))"
      ],
      "metadata": {
        "id": "m3dBN2BBgOaE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df.withColumn(\"title\", tolist_udf(col(\"title\")))\n",
        "df_2 = df_2.withColumn(\"label\", tolist_udf(col(\"news_outcome\")))"
      ],
      "metadata": {
        "id": "8CNyD2ARgRNL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "df_2 = df_2.withColumn(\"label\", df_2[\"label\"].cast(IntegerType()))"
      ],
      "metadata": {
        "id": "HCM3HKLIsI-e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = df_2.select(split(col(\"title\"),\",\").alias(\"TitleArray\"), \"label\", \"length_title\") \\\n",
        "    .drop(\"title\")\n",
        "df_3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiqSojxzgXEP",
        "outputId": "898b1d2b-6f00-4790-80b3-c4756e6cc684"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TitleArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- length_title: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hashing Term Frequency"
      ],
      "metadata": {
        "id": "EZYGG2uAnXo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency\n",
        "hashing = HashingTF(inputCol=\"TitleArray\", outputCol=\"TitleHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "ht7JMHaZgbKf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df = hashing.transform(df_3)"
      ],
      "metadata": {
        "id": "TQ8jlM7ugheu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvtwY_Yagi96",
        "outputId": "f516cbd2-da32-413a-9590-3b8d0022a106"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------+-----+------------+-------------------------------------------------------------------+\n",
            "|TitleArray                                                                            |label|length_title|TitleHashedValues                                                  |\n",
            "+--------------------------------------------------------------------------------------+-----+------------+-------------------------------------------------------------------+\n",
            "|[donald,  trump,  send,  embarrassing,  new,  year,  eve,  message,  disturb]         |1    |87          |(32,[4,9,11,13,22,25,28,30],[1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])     |\n",
            "|[drunk,  bragging,  trump,  staffer,  start,  russian,  collusion,  investigation]    |1    |91          |(32,[0,2,10,14,16,17,22,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])     |\n",
            "|[sheriff,  david,  clarke,  become,  internet,  joke,  threaten,  poke,  people,  eye]|1    |97          |(32,[3,5,6,7,10,13,16,22,24],[1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0])|\n",
            "+--------------------------------------------------------------------------------------+-----+------------+-------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = df_2.withColumn(\"text\", tolist_udf(col(\"text\")))"
      ],
      "metadata": {
        "id": "UPi9_eYMhTwu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df2 = text_df.select(split(col(\"text\"),\",\").alias(\"TextArray\"), \"label\", \"length_text\") \\\n",
        "    .drop(\"text\")\n",
        "text_df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63NU44dphwyl",
        "outputId": "8a132059-b7cf-4989-90a3-9a17e050ac79"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TextArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- length_text: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency - text\n",
        "hashing = HashingTF(inputCol=\"TextArray\", outputCol=\"TextHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "TZtCUsSziRNz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text = hashing.transform(text_df2)"
      ],
      "metadata": {
        "id": "O2s3sfc-iRvH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JgWiZsiePY",
        "outputId": "3fc75f0e-6e39-4bd0-e1a2-a38fd720acb9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-----------+--------------------+\n",
            "|           TextArray|label|length_text|    TextHashedValues|\n",
            "+--------------------+-----+-----------+--------------------+\n",
            "|[donald,  trump, ...|    1|       2825|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|    1|       1871|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|    1|       3533|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+-----+-----------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting IDF on the data set"
      ],
      "metadata": {
        "id": "8KsAfVzInfiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set \n",
        "idf = IDF(inputCol=\"TitleHashedValues\", outputCol=\"TitleFeatures\")\n",
        "idfModel = idf.fit(hashed_df)\n",
        "rescaledData = idfModel.transform(hashed_df)"
      ],
      "metadata": {
        "id": "Kc0QOqD_-LHj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cneaizHljY3R",
        "outputId": "bfa10ae0-2e39-4860-b2cd-da88dcf21e3f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+--------------------+--------------------+\n",
            "|          TitleArray|label|length_title|   TitleHashedValues|       TitleFeatures|\n",
            "+--------------------+-----+------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|          87|(32,[4,9,11,13,22...|(32,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|    1|          91|(32,[0,2,10,14,16...|(32,[0,2,10,14,16...|\n",
            "|[sheriff,  david,...|    1|          97|(32,[3,5,6,7,10,1...|(32,[3,5,6,7,10,1...|\n",
            "+--------------------+-----+------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set - text\n",
        "idf2 = IDF(inputCol=\"TextHashedValues\", outputCol=\"TextFeatures\")\n",
        "idfModel2 = idf2.fit(hashed_df_text)\n",
        "rescaledData2 = idfModel2.transform(hashed_df_text)"
      ],
      "metadata": {
        "id": "mC1as3TP-WzS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData2.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg3hn-BEkfc3",
        "outputId": "f4746983-090f-452c-8f94-65a7a06b46e4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-----------+--------------------+--------------------+\n",
            "|           TextArray|label|length_text|    TextHashedValues|        TextFeatures|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|       2825|(32,[0,1,2,3,4,6,...|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|    1|       1871|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|    1|       3533|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "PKyih3mnnjIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['TitleFeatures', 'length_title'], outputCol='features')"
      ],
      "metadata": {
        "id": "ixwCMH7tu2Ot"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner = clean_up.transform(rescaledData)"
      ],
      "metadata": {
        "id": "hM_Ji0G2u6zl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWjRWptKvhsD",
        "outputId": "fff40b99-22e3-422d-ba79-425cf9115d0f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+\n",
            "|          TitleArray|label|length_title|   TitleHashedValues|       TitleFeatures|            features|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|          87|(32,[4,9,11,13,22...|(32,[4,9,11,13,22...|(33,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|    1|          91|(32,[0,2,10,14,16...|(32,[0,2,10,14,16...|(33,[0,2,10,14,16...|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaner.randomSplit([0.7, 0.3])\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "1jJPMVGUnsh6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIAjQwCNseGp",
        "outputId": "5fe095a7-b145-4ac8-e317-f2d05217b213"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|          TitleArray|label|length_title|   TitleHashedValues|       TitleFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|[1,  percenter,  ...|    1|         131|(32,[3,5,6,9,10,1...|(32,[3,5,6,9,10,1...|(33,[3,5,6,9,10,1...|[-119.94141584677...|[0.54505805015146...|       0.0|\n",
            "|[10,  second,  sa...|    1|         110|(32,[6,9,11,14,15...|(32,[6,9,11,14,15...|(33,[6,9,11,14,15...|[-95.142036536482...|[0.49665498929029...|       1.0|\n",
            "|[100,  fed,  hill...|    1|          99|(32,[2,3,9,10,17,...|(32,[2,3,9,10,17,...|(33,[2,3,9,10,17,...|[-84.210456224000...|[0.29631795426934...|       1.0|\n",
            "|[12,  muslim,  mi...|    1|         103|(32,[1,5,8,12,15,...|(32,[1,5,8,12,15,...|(33,[1,5,8,12,15,...|[-108.63149746024...|[0.70291188423221...|       0.0|\n",
            "|[12,  tweet,  tru...|    1|          56|(32,[5,13,22,23,2...|(32,[5,13,22,23,2...|(33,[5,13,22,23,2...|[-50.780707446821...|[0.42587352498421...|       1.0|\n",
            "+--------------------+-----+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMomCwsssfU4",
        "outputId": "b8f73dd2-9d0c-4ee9-d9bc-71c2e812c8d3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.639535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature vectors\n",
        "clean_up2 = VectorAssembler(inputCols=['TextFeatures', 'length_text'], outputCol='features')\n",
        "cleaner_text = clean_up2.transform(rescaledData2)"
      ],
      "metadata": {
        "id": "UkYpq-jCwIRa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner_text.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4COXQudwOHY",
        "outputId": "5db48edd-9e66-4aba-bc21-ecee40909ed8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-----------+--------------------+--------------------+--------------------+\n",
            "|           TextArray|label|length_text|    TextHashedValues|        TextFeatures|            features|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|       2825|(32,[0,1,2,3,4,6,...|(32,[0,1,2,3,4,6,...|[0.90043953270749...|\n",
            "|[house,  intellig...|    1|       1871|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|[0.65486511469635...|\n",
            "+--------------------+-----+-----------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaner_text.randomSplit([0.7, 0.3])\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "A3Hj11rdwttu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1ZxNqfGw5s-",
        "outputId": "3e529373-df4b-4b67-d80d-4c72a2d792bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|TextArray|label|length_text|TextHashedValues|        TextFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2141850090944...|[0.47394806453468...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2141850090944...|[0.47394806453468...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2141850090944...|[0.47394806453468...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2141850090944...|[0.47394806453468...|       1.0|\n",
            "|       []|    1|          2| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-1.2141850090944...|[0.47394806453468...|       1.0|\n",
            "+---------+-----+-----------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKiLHf7qw6u2",
        "outputId": "abd27574-d800-42c5-ef01-35d9751ef8eb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.659106\n"
          ]
        }
      ]
    }
  ]
}