{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF_and_NB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vu9budV6MR0",
        "outputId": "b5fcc22b-8f8b-4f1d-8860-a5b2f0ae5e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/88.7 kB 16%] [Connecting to cloud\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,496 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,733 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,167 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,953 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,001 kB]\n",
            "Fetched 12.9 MB in 4s (3,436 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Hashing\").getOrCreate()"
      ],
      "metadata": {
        "id": "N0f4vTT96OgS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
      ],
      "metadata": {
        "id": "BZCl6w8o6hgE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSV\n",
        "from pyspark import SparkFiles\n",
        "df = spark.read.csv(SparkFiles.get(\"/content/news.csv\"),sep=\",\", escape='\"', encoding=\"utf-8\", quote='\"',  header=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBpqmVWE6mNi",
        "outputId": "d941cb53-2734-4bbf-cb3b-acab6a531192"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|               title|                text|subject|      date|news_outcome|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|['donald', 'trump...|['donald', 'trump...|   News|31/12/2017|           1|\n",
            "|['drunk', 'braggi...|['house', 'intell...|   News|31/12/2017|           1|\n",
            "|['sheriff', 'davi...|['friday', 'revea...|   News|30/12/2017|           1|\n",
            "|['trump', 'obsess...|['christmas', 'da...|   News|29/12/2017|           1|\n",
            "|['pope', 'francis...|['pope', 'francis...|   News|25/12/2017|           1|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "df = df.withColumn('length', length(df['title']))\n",
        "df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYl4gaV4t_Ig",
        "outputId": "3244ed65-eef3-4c91-b7a6-3654c3c8453f"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+----------+------------+------+\n",
            "|               title|                text|subject|      date|news_outcome|length|\n",
            "+--------------------+--------------------+-------+----------+------------+------+\n",
            "|['donald', 'trump...|['donald', 'trump...|   News|31/12/2017|           1|    87|\n",
            "|['drunk', 'braggi...|['house', 'intell...|   News|31/12/2017|           1|    91|\n",
            "|['sheriff', 'davi...|['friday', 'revea...|   News|30/12/2017|           1|    97|\n",
            "+--------------------+--------------------+-------+----------+------------+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezuEienogLQ5",
        "outputId": "38540d6a-9a07-4349-ba94-821761249741"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- subject: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- news_outcome: string (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changing the title type to array\n",
        "from pyspark.sql.functions import udf, col, split\n",
        "\n",
        "tolist_udf = udf(lambda x: x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))"
      ],
      "metadata": {
        "id": "m3dBN2BBgOaE"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df.withColumn(\"title\", tolist_udf(col(\"title\")))\n",
        "df_2 = df_2.withColumn(\"label\", tolist_udf(col(\"news_outcome\")))"
      ],
      "metadata": {
        "id": "8CNyD2ARgRNL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "df_2 = df_2.withColumn(\"label\", df_2[\"label\"].cast(IntegerType()))"
      ],
      "metadata": {
        "id": "HCM3HKLIsI-e"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = df_2.select(split(col(\"title\"),\",\").alias(\"TitleArray\"), \"label\", \"length\") \\\n",
        "    .drop(\"title\")\n",
        "df_3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiqSojxzgXEP",
        "outputId": "7299f59a-d23a-452d-e873-aa02932e359f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TitleArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hashing Term Frequency"
      ],
      "metadata": {
        "id": "EZYGG2uAnXo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency\n",
        "hashing = HashingTF(inputCol=\"TitleArray\", outputCol=\"TitleHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "ht7JMHaZgbKf"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df = hashing.transform(df_3)"
      ],
      "metadata": {
        "id": "TQ8jlM7ugheu"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df.show(3, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvtwY_Yagi96",
        "outputId": "88dc73f3-c7e7-4f95-eb76-2a260dbfed48"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------+-----+------+-------------------------------------------------------------------+\n",
            "|TitleArray                                                                            |label|length|TitleHashedValues                                                  |\n",
            "+--------------------------------------------------------------------------------------+-----+------+-------------------------------------------------------------------+\n",
            "|[donald,  trump,  send,  embarrassing,  new,  year,  eve,  message,  disturb]         |1    |87    |(32,[4,9,11,13,22,25,28,30],[1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])     |\n",
            "|[drunk,  bragging,  trump,  staffer,  start,  russian,  collusion,  investigation]    |1    |91    |(32,[0,2,10,14,16,17,22,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])     |\n",
            "|[sheriff,  david,  clarke,  become,  internet,  joke,  threaten,  poke,  people,  eye]|1    |97    |(32,[3,5,6,7,10,13,16,22,24],[1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0])|\n",
            "+--------------------------------------------------------------------------------------+-----+------+-------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = df_2.withColumn(\"text\", tolist_udf(col(\"text\")))"
      ],
      "metadata": {
        "id": "UPi9_eYMhTwu"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df2 = text_df.select(split(col(\"text\"),\",\").alias(\"TextArray\"), \"label\", \"length\") \\\n",
        "    .drop(\"text\")\n",
        "text_df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63NU44dphwyl",
        "outputId": "8a8b447d-92de-464c-ae68-59ccf3fbde99"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TextArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- label: integer (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency - text\n",
        "hashing = HashingTF(inputCol=\"TextArray\", outputCol=\"TextHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "TZtCUsSziRNz"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text = hashing.transform(text_df2)"
      ],
      "metadata": {
        "id": "O2s3sfc-iRvH"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JgWiZsiePY",
        "outputId": "bd864171-ade3-4893-f67d-f5f83b78c1e3"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+--------------------+\n",
            "|           TextArray|label|length|    TextHashedValues|\n",
            "+--------------------+-----+------+--------------------+\n",
            "|[donald,  trump, ...|    1|    87|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|    1|    91|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|    1|    97|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+-----+------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting IDF on the data set"
      ],
      "metadata": {
        "id": "8KsAfVzInfiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set \n",
        "idf = IDF(inputCol=\"TitleHashedValues\", outputCol=\"TitleFeatures\")\n",
        "idfModel = idf.fit(hashed_df)\n",
        "rescaledData = idfModel.transform(hashed_df)"
      ],
      "metadata": {
        "id": "Kc0QOqD_-LHj"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cneaizHljY3R",
        "outputId": "0f7cab04-4a81-4a43-a01a-0ee91693586b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "|          TitleArray|label|length|   TitleHashedValues|       TitleFeatures|\n",
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|    87|(32,[4,9,11,13,22...|(32,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|    1|    91|(32,[0,2,10,14,16...|(32,[0,2,10,14,16...|\n",
            "|[sheriff,  david,...|    1|    97|(32,[3,5,6,7,10,1...|(32,[3,5,6,7,10,1...|\n",
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set - text\n",
        "idf2 = IDF(inputCol=\"TextHashedValues\", outputCol=\"TextFeatures\")\n",
        "idfModel2 = idf2.fit(hashed_df_text)\n",
        "rescaledData2 = idfModel2.transform(hashed_df_text)"
      ],
      "metadata": {
        "id": "mC1as3TP-WzS"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData2.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg3hn-BEkfc3",
        "outputId": "c03185e0-183e-47a7-e48b-e85077fc9434"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "|           TextArray|label|length|    TextHashedValues|        TextFeatures|\n",
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|    87|(32,[0,1,2,3,4,6,...|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|    1|    91|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|    1|    97|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "PKyih3mnnjIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['TitleFeatures', 'length'], outputCol='features')"
      ],
      "metadata": {
        "id": "ixwCMH7tu2Ot"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner = clean_up.transform(rescaledData)"
      ],
      "metadata": {
        "id": "hM_Ji0G2u6zl"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWjRWptKvhsD",
        "outputId": "fd3b408f-414c-4a36-f7b0-e7389993e7ef"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+--------------------+--------------------+--------------------+\n",
            "|          TitleArray|label|length|   TitleHashedValues|       TitleFeatures|            features|\n",
            "+--------------------+-----+------+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|    87|(32,[4,9,11,13,22...|(32,[4,9,11,13,22...|(33,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|    1|    91|(32,[0,2,10,14,16...|(32,[0,2,10,14,16...|(33,[0,2,10,14,16...|\n",
            "+--------------------+-----+------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaner.randomSplit([0.7, 0.3])\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "1jJPMVGUnsh6"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIAjQwCNseGp",
        "outputId": "366d3f09-7303-433a-c716-e890a3d23610"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|          TitleArray|label|length|   TitleHashedValues|       TitleFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|[1,  million,  do...|    1|    94|(32,[1,7,11,15,21...|(32,[1,7,11,15,21...|(33,[1,7,11,15,21...|[-92.468299837790...|[0.70809060732337...|       0.0|\n",
            "|[10,  second,  sa...|    1|   110|(32,[6,9,11,14,15...|(32,[6,9,11,14,15...|(33,[6,9,11,14,15...|[-95.156499655143...|[0.49189732071980...|       1.0|\n",
            "|[10,  u,  navy,  ...|    1|   100|(32,[3,5,10,11,13...|(32,[3,5,10,11,13...|(33,[3,5,10,11,13...|[-97.878722368196...|[0.52663515834801...|       0.0|\n",
            "|[100,  fed,  hill...|    1|    99|(32,[2,3,9,10,17,...|(32,[2,3,9,10,17,...|(33,[2,3,9,10,17,...|[-84.270607977606...|[0.29494426267814...|       1.0|\n",
            "|[100,  million,  ...|    1|    94|(32,[3,8,9,10,12,...|(32,[3,8,9,10,12,...|(33,[3,8,9,10,12,...|[-80.672719544697...|[0.38652318182223...|       1.0|\n",
            "+--------------------+-----+------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMomCwsssfU4",
        "outputId": "99ff263c-7655-4f00-d9b0-8384389abdb0"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.638448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature vectors\n",
        "clean_up2 = VectorAssembler(inputCols=['TextFeatures', 'length'], outputCol='features')\n",
        "cleaner_text = clean_up2.transform(rescaledData2)"
      ],
      "metadata": {
        "id": "UkYpq-jCwIRa"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner_text.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4COXQudwOHY",
        "outputId": "2ed1f6d1-0ae6-47e8-fdc1-26fddf07030b"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+--------------------+--------------------+--------------------+\n",
            "|           TextArray|label|length|    TextHashedValues|        TextFeatures|            features|\n",
            "+--------------------+-----+------+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|    1|    87|(32,[0,1,2,3,4,6,...|(32,[0,1,2,3,4,6,...|[0.90043953270749...|\n",
            "|[house,  intellig...|    1|    91|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|[0.65486511469635...|\n",
            "+--------------------+-----+------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaner_text.randomSplit([0.7, 0.3])\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "A3Hj11rdwttu"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1ZxNqfGw5s-",
        "outputId": "9a164bb4-ffa6-4702-a9ef-7cd08fbc325b"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|TextArray|label|length|TextHashedValues|        TextFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+---------+-----+------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|       []|    1|    35| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-8.5429441258376...|[0.17449378052233...|       1.0|\n",
            "|       []|    1|    47| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-11.119183442055...|[0.11334766184906...|       1.0|\n",
            "|       []|    1|    56| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-13.051362929219...|[0.08060483914375...|       1.0|\n",
            "|       []|    1|    58| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-13.480736148588...|[0.07460786932016...|       1.0|\n",
            "|       []|    1|    59| (32,[28],[1.0])|(32,[28],[0.05212...|(33,[28,32],[0.05...|[-13.695422758273...|[0.07176562163540...|       1.0|\n",
            "+---------+-----+------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKiLHf7qw6u2",
        "outputId": "7c7b8b37-38c5-4067-a65e-120cd7f450ea"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.606742\n"
          ]
        }
      ]
    }
  ]
}