{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vu9budV6MR0",
        "outputId": "b5fcc22b-8f8b-4f1d-8860-a5b2f0ae5e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/88.7 kB 16%] [Connecting to cloud\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,496 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,733 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,167 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,953 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,001 kB]\n",
            "Fetched 12.9 MB in 4s (3,436 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Hashing\").getOrCreate()"
      ],
      "metadata": {
        "id": "N0f4vTT96OgS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
      ],
      "metadata": {
        "id": "BZCl6w8o6hgE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSV\n",
        "from pyspark import SparkFiles\n",
        "df = spark.read.csv(SparkFiles.get(\"/content/news.csv\"),sep=\",\", escape='\"', encoding=\"utf-8\", quote='\"',  header=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBpqmVWE6mNi",
        "outputId": "d941cb53-2734-4bbf-cb3b-acab6a531192"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|               title|                text|subject|      date|news_outcome|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "|['donald', 'trump...|['donald', 'trump...|   News|31/12/2017|           1|\n",
            "|['drunk', 'braggi...|['house', 'intell...|   News|31/12/2017|           1|\n",
            "|['sheriff', 'davi...|['friday', 'revea...|   News|30/12/2017|           1|\n",
            "|['trump', 'obsess...|['christmas', 'da...|   News|29/12/2017|           1|\n",
            "|['pope', 'francis...|['pope', 'francis...|   News|25/12/2017|           1|\n",
            "+--------------------+--------------------+-------+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezuEienogLQ5",
        "outputId": "0353f8b3-47ea-47cb-ac44-5c7e501c3d20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- title: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- subject: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- news_outcome: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf, col, split\n",
        "\n",
        "tolist_udf = udf(lambda x: x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))"
      ],
      "metadata": {
        "id": "m3dBN2BBgOaE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df.withColumn(\"title\", tolist_udf(col(\"title\")))"
      ],
      "metadata": {
        "id": "8CNyD2ARgRNL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = df_2.select(split(col(\"title\"),\",\").alias(\"TitleArray\")) \\\n",
        "    .drop(\"title\")\n",
        "df_3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiqSojxzgXEP",
        "outputId": "7c68aeca-1acf-4038-b065-e090a8c57a28"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TitleArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency\n",
        "hashing = HashingTF(inputCol=\"TitleArray\", outputCol=\"TitleHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "ht7JMHaZgbKf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df = hashing.transform(df_3)"
      ],
      "metadata": {
        "id": "TQ8jlM7ugheu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df.show(3, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvtwY_Yagi96",
        "outputId": "f20d7e7e-0e33-40fa-e141-d2a7beb29b79"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "|TitleArray                                                                            |TitleHashedValues                                                  |\n",
            "+--------------------------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "|[donald,  trump,  send,  embarrassing,  new,  year,  eve,  message,  disturb]         |(32,[4,9,11,13,22,25,28,30],[1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])     |\n",
            "|[drunk,  bragging,  trump,  staffer,  start,  russian,  collusion,  investigation]    |(32,[0,2,10,14,16,17,22,29],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])     |\n",
            "|[sheriff,  david,  clarke,  become,  internet,  joke,  threaten,  poke,  people,  eye]|(32,[3,5,6,7,10,13,16,22,24],[1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0])|\n",
            "+--------------------------------------------------------------------------------------+-------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = df_2.withColumn(\"text\", tolist_udf(col(\"text\")))"
      ],
      "metadata": {
        "id": "UPi9_eYMhTwu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df2 = text_df.select(split(col(\"text\"),\",\").alias(\"TextArray\"), \"text\") \\\n",
        "    .drop(\"text\")\n",
        "text_df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63NU44dphwyl",
        "outputId": "ab8088f6-266a-4d23-85c4-0b540f760d07"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- TextArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hashing term frequency\n",
        "hashing = HashingTF(inputCol=\"TextArray\", outputCol=\"TextHashedValues\", numFeatures=pow(2,5))"
      ],
      "metadata": {
        "id": "TZtCUsSziRNz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text = hashing.transform(text_df2)"
      ],
      "metadata": {
        "id": "O2s3sfc-iRvH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashed_df_text.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JgWiZsiePY",
        "outputId": "279ad187-0bcc-4e7d-9f8c-39bf6f9eca24"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|           TextArray|    TextHashedValues|\n",
            "+--------------------+--------------------+\n",
            "|[donald,  trump, ...|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set \n",
        "idf = IDF(inputCol=\"TitleHashedValues\", outputCol=\"TitleFeatures\")\n",
        "idfModel = idf.fit(hashed_df)\n",
        "rescaledData = idfModel.transform(hashed_df)"
      ],
      "metadata": {
        "id": "Kc0QOqD_-LHj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cneaizHljY3R",
        "outputId": "72d4af08-58e0-43e9-a982-51fd939bc2a2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|          TitleArray|   TitleHashedValues|       TitleFeatures|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|(32,[4,9,11,13,22...|(32,[4,9,11,13,22...|\n",
            "|[drunk,  bragging...|(32,[0,2,10,14,16...|(32,[0,2,10,14,16...|\n",
            "|[sheriff,  david,...|(32,[3,5,6,7,10,1...|(32,[3,5,6,7,10,1...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the IDF on the data set \n",
        "idf2 = IDF(inputCol=\"TextHashedValues\", outputCol=\"TextFeatures\")\n",
        "idfModel2 = idf2.fit(hashed_df_text)\n",
        "rescaledData2 = idfModel2.transform(hashed_df_text)"
      ],
      "metadata": {
        "id": "mC1as3TP-WzS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescaledData2.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg3hn-BEkfc3",
        "outputId": "7272dda3-583b-45c1-fbb6-10cf5dfb348d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|           TextArray|    TextHashedValues|        TextFeatures|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|[donald,  trump, ...|(32,[0,1,2,3,4,6,...|(32,[0,1,2,3,4,6,...|\n",
            "|[house,  intellig...|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "|[friday,  reveal,...|(32,[0,1,2,3,4,5,...|(32,[0,1,2,3,4,5,...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}